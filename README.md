# Image-Text-Inference-LLaVA
This repository contains a Python script for running multimodal inference using the LLaVA v1.5 model. It accepts an image and a prompt, and returns a generated response using vision-language capabilities.
